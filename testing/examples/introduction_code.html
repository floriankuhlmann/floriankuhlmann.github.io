<!DOCTYPE html>
<html>
<head>
    <title>introduction</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1, maximum-scale=1">
    <script src="js/third_party/three.js/three.min.js"></script>
    <script src="js/artoolkit.debug.js"></script>
    <script src="js/artoolkit.api.js"></script>
    <script src="js/artoolkit.three.js"></script>
    <style>
        html,body {
            margin: 0;
            padding: 0;
            width: 100%;
            text-align: center;
            overflow-x: hidden;
        }
        .portrait canvas {
            transform-origin: 0 0;
            transform: rotate(-90deg) translateX(-100%);
        }
        .desktop canvas {
            transform: scale(-1, 1);
        }
    </style>

</head>
<body>

<script>

    // Weâ€™ll get a video from your device camera using the getUserMedia API.
    // The simple way to getthis is to use a helper function in JSARToolKit5: ARController.getUserMedia(options).
    // The onSuccess callback in the options object gets called with a ready-to-use video element.
    var markerRoot;
    var video = ARController.getUserMedia({
        maxARVideoSize: 320, // do AR processing on scaled down video of this size
        facing: "environment",
        onSuccess: function(video) {
            console.log('got video', video);
        }
    });

    var arController = new ARController(video, 'Data/camera_para.dat');
    arController.videoHeight = 480;
    arController.videoWidth = 640;
    arController.onload = function() {

        console.log('ARController ready for use', arController);

        document.body.className = arController.orientation;

        var renderer = new THREE.WebGLRenderer({antialias: true});
        if (arController.orientation === 'portrait') {
            var w = (window.innerWidth / arController.videoHeight) * arController.videoWidth;
            var h = window.innerWidth;
            renderer.setSize(w, h);
            renderer.domElement.style.paddingBottom = (w-h) + 'px';
        } else {
            if (/Android|mobile|iPad|iPhone/i.test(navigator.userAgent)) {
                renderer.setSize(window.innerWidth, (window.innerWidth / arController.videoWidth) * arController.videoHeight);
            } else {
                renderer.setSize(arController.videoWidth, arController.videoHeight);
                document.body.className += ' desktop';
            }
        }

        document.body.insertBefore(renderer.domElement, document.body.firstChild);

        var rotationV = 0;
        var rotationTarget = 0;

        renderer.domElement.addEventListener('click', function(ev) {
            ev.preventDefault();
            rotationTarget += 1;
        }, false);


        var geometry	= new THREE.CubeGeometry(1,1,1);
        var material	= new THREE.MeshNormalMaterial({
            transparent : true,
            opacity: 0.5,
            side: THREE.DoubleSide
        });

        new THREE.MeshNormalMaterial({transparent : true, opacity: 0.5, side: THREE.DoubleSide});

        var materialArray = [];
        materialArray.push(new THREE.MeshNormalMaterial({transparent : true, opacity: 0.5, side: THREE.DoubleSide}));
        materialArray.push(new THREE.MeshNormalMaterial({transparent : true, opacity: 0.5, side: THREE.DoubleSide}));
        materialArray.push(new THREE.MeshNormalMaterial({transparent : true, opacity: 0.5, side: THREE.DoubleSide}));
        materialArray.push(new THREE.MeshNormalMaterial({transparent : true, opacity: 0.5, side: THREE.DoubleSide}));
        materialArray.push(new THREE.MeshBasicMaterial( { map: THREE.ImageUtils.loadTexture( 'images/transformation_of_thinking_text.jpg' ), transparent: true, opacity: 0.75, color: 0xFFFFFF }));
        materialArray.push(new THREE.MeshNormalMaterial({transparent : true, opacity: 0.5, side: THREE.DoubleSide}));
        var MovingCubeMat = new THREE.MeshFaceMaterial(materialArray);
        var MovingCubeGeom = new THREE.CubeGeometry( 1, 1, 1, 1, 1, 1, materialArray );
        var sphere = new THREE.Mesh( MovingCubeGeom, MovingCubeMat );


        sphere.scale.set(210,290,10);

        sphere.position.x = 105;
        sphere.position.y = 145;
        sphere.position.z = 50;

        // init scene and camera
        var scene	= new THREE.Scene();



        arController.loadNFTMarker('DataNFT/freedom', function(markerId) {
            markerRoot = arController.createThreeNFTMarker(markerId);
            markerRoot.add(sphere);
            scene.add(markerRoot);

        });
        console.log("markerRoot ", markerRoot);

        //////////////////////////////////////////////////////////////////////////////////
        //		add an object in the scene
        //////////////////////////////////////////////////////////////////////////////////

        var torus = new THREE.Mesh(
                new THREE.TorusGeometry(0.3, 0.2, 8, 8),
                new THREE.MeshNormalMaterial()
        );
        torus.material.shading = THREE.FlatShading;
        torus.position.z = 0.5;
        torus.rotation.x = Math.PI/2;




        var tick = function() {
            console.log("arScene.process in nft_three.js");
            scene.process();

            rotationV += (rotationTarget - sphere.rotation.z) * 0.05;
            sphere.rotation.z += rotationV;
            torus.rotation.y += rotationV;
            rotationV *= 0.8;

            scene.renderOn(renderer);
            requestAnimationFrame(tick);
        };

        tick();

    };






</script>

</body>
</html>